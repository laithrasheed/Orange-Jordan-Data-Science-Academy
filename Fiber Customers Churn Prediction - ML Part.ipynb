{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db5e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3de54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GOVERNORATE</th>\n",
       "      <th>Customer with orange_MONTHS</th>\n",
       "      <th>CUSTOMER_AGE_MONTHS</th>\n",
       "      <th>CUSTOMER_GENDER</th>\n",
       "      <th>COMMITMENT</th>\n",
       "      <th>COMMITMENT_FG</th>\n",
       "      <th>OF_SPEED</th>\n",
       "      <th>OF_PREV_SPEED</th>\n",
       "      <th>MIGRATION_FLAG</th>\n",
       "      <th>...</th>\n",
       "      <th>LAST_POWER_VALIDATION</th>\n",
       "      <th>LAST_LINK_PRIORITY</th>\n",
       "      <th>Disconnection_TOTAL_MAX_day</th>\n",
       "      <th>Disconnection_TOTAL_MIN_day</th>\n",
       "      <th>Disconnection_TOTAL_SUM_Month</th>\n",
       "      <th>Disconnection_TOTAL_MEAN_Month</th>\n",
       "      <th>GB_TOTAL_CONSUMPTION_Month1</th>\n",
       "      <th>GB_TOTAL_CONSUMPTION_Month2</th>\n",
       "      <th>GB_TOTAL_CONSUMPTION_Month3</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>West Amman</td>\n",
       "      <td>48.741935</td>\n",
       "      <td>567.677419</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>645.685532</td>\n",
       "      <td>561.726552</td>\n",
       "      <td>519.477249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>West Amman</td>\n",
       "      <td>44.838710</td>\n",
       "      <td>740.580645</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>174.360611</td>\n",
       "      <td>159.508825</td>\n",
       "      <td>145.229521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>West Amman</td>\n",
       "      <td>44.612903</td>\n",
       "      <td>531.096774</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Regular</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>299.379466</td>\n",
       "      <td>319.849905</td>\n",
       "      <td>257.353694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Balqa</td>\n",
       "      <td>43.741935</td>\n",
       "      <td>645.612903</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>477.543451</td>\n",
       "      <td>791.806873</td>\n",
       "      <td>569.299840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID GOVERNORATE  Customer with orange_MONTHS  CUSTOMER_AGE_MONTHS  \\\n",
       "0   1  West Amman                    48.741935           567.677419   \n",
       "1   2  West Amman                    44.838710           740.580645   \n",
       "2   3  West Amman                    44.612903           531.096774   \n",
       "3   4       Balqa                    43.741935           645.612903   \n",
       "\n",
       "  CUSTOMER_GENDER  COMMITMENT  COMMITMENT_FG  OF_SPEED  OF_PREV_SPEED  \\\n",
       "0               M          24              1       200          100.0   \n",
       "1               M          24              0       100          100.0   \n",
       "2               M          24              1       200          100.0   \n",
       "3               M          24              0       200          100.0   \n",
       "\n",
       "  MIGRATION_FLAG  ... LAST_POWER_VALIDATION LAST_LINK_PRIORITY  \\\n",
       "0              y  ...              Abnormal            Regular   \n",
       "1              y  ...                  None            Regular   \n",
       "2              y  ...                  None            Regular   \n",
       "3              y  ...                  None            Regular   \n",
       "\n",
       "  Disconnection_TOTAL_MAX_day Disconnection_TOTAL_MIN_day  \\\n",
       "0                         1.0                         1.0   \n",
       "1                         1.0                         1.0   \n",
       "2                         2.0                         1.0   \n",
       "3                         1.0                         1.0   \n",
       "\n",
       "   Disconnection_TOTAL_SUM_Month  Disconnection_TOTAL_MEAN_Month  \\\n",
       "0                           32.0                        1.000000   \n",
       "1                            4.0                        1.000000   \n",
       "2                            8.0                        1.333333   \n",
       "3                            6.0                        1.000000   \n",
       "\n",
       "   GB_TOTAL_CONSUMPTION_Month1  GB_TOTAL_CONSUMPTION_Month2  \\\n",
       "0                   645.685532                   561.726552   \n",
       "1                   174.360611                   159.508825   \n",
       "2                   299.379466                   319.849905   \n",
       "3                   477.543451                   791.806873   \n",
       "\n",
       "   GB_TOTAL_CONSUMPTION_Month3  TARGET  \n",
       "0                   519.477249       0  \n",
       "1                   145.229521       0  \n",
       "2                   257.353694       0  \n",
       "3                   569.299840       0  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "# note that this project can't be reproducable, due to the privacy policy of publishing this dtaset! \n",
    "df = pd.read_excel('FTTH-DataSet.xlsx')\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283abd2",
   "metadata": {},
   "source": [
    "###### it's a good practice to split the dataset into training, validation, and testing sets before applying any data analysis or modeling techniques. This helps to evaluate the performance of the model on unseen data and avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4537663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the needed library\n",
    "from sklearn.model_selection import train_test_split\n",
    "# splitting the datasest into 3 datasets: train, validate, and test\n",
    "# the stratify parameter is used to ensure that the target  is evenly distributed.\n",
    "train, test = train_test_split(df, test_size=.2, random_state=42, stratify=df['TARGET'])\n",
    "train, val = train_test_split(train, test_size=.1, random_state=42, stratify=train['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547504ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape is: (68023, 22) \n",
      " Validation Dataset Shape is: (7559, 22) \n",
      " Testing Dataset Shape is: (18896, 22)\n"
     ]
    }
   ],
   "source": [
    "#Let's output the shapes of the three datasets: training, validation, and testing :)\n",
    "print('Training Dataset Shape is:', train.shape, '\\n','Validation Dataset Shape is:' , val.shape,'\\n','Testing Dataset Shape is:' , test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8705a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Save the training, validation, and testing datasets to separate CSV files :)\n",
    "train.to_csv('train.csv', index=False)\n",
    "val.to_csv('val.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d28f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the training, validation, and testing datasets from separate CSV files generated previously\n",
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('val.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d965fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the needed libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# let's define a function that perform the data cleaning steps\n",
    "def clean (data):\n",
    "    #lets's drop the columns that we think it is not needed\n",
    "    data = data.drop(['ID', 'OF_PREV_SPEED', 'LAST_LINK_QUALITY', 'LAST_LINK_STATUS', 'LAST_POWER_VALIDATION', 'LAST_LINK_PRIORITY', 'Disconnection_TOTAL_MAX_day', 'Disconnection_TOTAL_MIN_day', 'Disconnection_TOTAL_SUM_Month', 'Disconnection_TOTAL_MEAN_Month'], axis=1)\n",
    "    # we are going to fill the missing data with most common value for each categorical and numerical values    \n",
    "    data =data.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "    # we need to import preprocessing fron sciket learn library, to use label encoding for handling the categorical values\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    # applying the label encoding for the follwing 3 features that have categorical values \n",
    "    data['GOVERNORATE']= label_encoder.fit_transform(data['GOVERNORATE'])\n",
    "    data['CUSTOMER_GENDER']= label_encoder.fit_transform(data['CUSTOMER_GENDER'])\n",
    "    data['MIGRATION_FLAG']= label_encoder.fit_transform(data['MIGRATION_FLAG'])\n",
    "    # let's define a variable that stores all the columns we are in need to handle its scale\n",
    "    columns_to_scale = ['GOVERNORATE', 'Customer with orange_MONTHS', 'CUSTOMER_AGE_MONTHS','CUSTOMER_GENDER', 'COMMITMENT', 'COMMITMENT_FG', 'OF_SPEED','MIGRATION_FLAG', 'GB_TOTAL_CONSUMPTION_Month1','GB_TOTAL_CONSUMPTION_Month2', 'GB_TOTAL_CONSUMPTION_Month3', 'TARGET']\n",
    "    # we are going to use MinMaxScaler to handle the distribution of the data\n",
    "    # we need to import its library\n",
    "    # let's define another varabile that store the MinMaxScaler function\n",
    "    scaler = MinMaxScaler()\n",
    "    # applying scaler to the defined columns\n",
    "    data[columns_to_scale] = scaler.fit_transform(data[columns_to_scale])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee24686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's apply the cleaning to the all of the 3 datasets each separatly :)\n",
    "train = clean(train)\n",
    "val = clean(val)\n",
    "test = clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e855b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries for Random Forest Algorithim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def rf (data):\n",
    "    # let's strt to deal with the IMBALANCE we have\n",
    "    # the following code counts the number of churned customers(class 1), and the number of un-churned custoemrs( class 0 )\n",
    "    count_class_0, count_class_1 = data.TARGET.value_counts()\n",
    "    data_class_0 = data[data['TARGET'] == 0]\n",
    "    data_class_1 = data[data['TARGET'] == 1]\n",
    "    # we are going to apply the oversampling technique to class 1 in order to deal with the Imbalance\n",
    "    data_class_1_over = data_class_1.sample(count_class_0, replace=True) # replace = True , to prevent duplicated outputs\n",
    "    data_test_over = pd.concat([data_class_0, data_class_1_over], axis=0)\n",
    "    # let's define  X and y \n",
    "    X = data_test_over.drop('TARGET',axis= 1)\n",
    "    y = data_test_over['TARGET']\n",
    "    # let's split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y )\n",
    "    model = RandomForestClassifier().fit(X_train, y_train)\n",
    "    # let's predict the target\n",
    "    y_pred = model.predict(X_test)\n",
    "    # finally, let's output the f1-score , we used it because of the imbalance case of the dataset\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca5cf23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99996304371928"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b49b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5051f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ed3d4",
   "metadata": {},
   "source": [
    "###### We can  use the same custom functions defined to predict any other models , by redefining the model variable and importing the needed libraries first.\n",
    "\n",
    "###### you can find more repositories in my growing up GitHub Profile :) \n",
    "https://github.com/laithrasheed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a662aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
